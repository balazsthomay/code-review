{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5822e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from IPython.display import Markdown, display\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "from typing import Optional, List\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4398f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51840628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "OpenRouter API Key exists and begins sk-or-v1\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if openrouter_api_key:\n",
    "    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenRouter API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c333c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grok_code_fast_1=LitellmModel(model=\"openrouter/x-ai/grok-code-fast-1\", api_key=openrouter_api_key)\n",
    "grok_4_fast=LitellmModel(model=\"openrouter/x-ai/grok-4-fast\", api_key=openrouter_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc0072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugFinding(BaseModel):\n",
    "    title: str = Field(description=\"Brief name for the bug\")\n",
    "    description: str = Field(description=\"Detailed explanation\")\n",
    "    severity: int = Field(description=\"Severity 1-10\")\n",
    "    file: str = Field(description=\"File path\")\n",
    "    relevant_lines: list[int] = Field(description=\"Line numbers\")\n",
    "    suggested_fix: str = Field(description=\"Recommended solution\")\n",
    "\n",
    "class VulnerabilityFinding(BaseModel):\n",
    "    title: str = Field(description=\"Brief name for the vulnerability\")\n",
    "    description: str = Field(description=\"Detailed explanation\")\n",
    "    severity: int = Field(description=\"Severity 1-10\")\n",
    "    file: str = Field(description=\"File path\")\n",
    "    relevant_lines: list[int] = Field(description=\"Line numbers\")\n",
    "    suggested_fix: str = Field(description=\"Recommended solution\")\n",
    "    cve_reference: str | None = Field(default=None, description=\"CVE ID if applicable\")\n",
    "\n",
    "class BestPracticeFinding(BaseModel):\n",
    "    title: str = Field(description=\"Brief name for the best practice violation\")\n",
    "    description: str = Field(description=\"Detailed explanation\")\n",
    "    severity: int = Field(description=\"Severity 1-10\")\n",
    "    file: str = Field(description=\"File path\")\n",
    "    relevant_lines: list[int] = Field(description=\"Line numbers\")\n",
    "    suggested_fix: str = Field(description=\"Recommended solution\")\n",
    "    \n",
    "class TestGap(BaseModel):\n",
    "    function_name: str = Field(description=\"Name of the function/method lacking tests\")\n",
    "    file: str = Field(description=\"File containing the untested code\")\n",
    "    lines: list[int] = Field(description=\"Line numbers of the untested code\")\n",
    "    missing_scenarios: list[str] = Field(description=\"Specific test cases that should be added, e.g., ['edge case: empty input', 'error handling: invalid type']\")\n",
    "    priority: int = Field(description=\"Priority 1-10, based on code criticality\")\n",
    "    suggested_test_approach: str = Field(description=\"How to test this (unit test, integration test, etc.)\")\n",
    "    \n",
    "class CodeAnalyzerOutput(BaseModel):\n",
    "    findings: list[BugFinding] = Field(description=\"Bugs and anti-patterns found\")\n",
    "\n",
    "class SecurityOutput(BaseModel):\n",
    "    findings: list[VulnerabilityFinding] = Field(description=\"Security vulnerabilities found\")\n",
    "\n",
    "class BestPracticesOutput(BaseModel):\n",
    "    findings: list[BestPracticeFinding] = Field(description=\"Style and best practice violations\")\n",
    "\n",
    "class TestCoverageOutput(BaseModel):\n",
    "    findings: list[TestGap] = Field(description=\"Testing gaps found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc14d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "code_analyzer_instructions = \"\"\"You are a Code Analyzer agent reviewing a pull request diff. \n",
    "Identify bugs and anti-patterns including: logic errors, unhandled edge cases, null/undefined access, type mismatches, off-by-one errors, resource leaks (unclosed files/cursors/connections), infinite loops, missing error handling (no try-except blocks), code duplication, and overly complex functions. \n",
    "For each issue found, specify the exact lines, severity (1-10), and a clear fix.\"\"\"\n",
    "\n",
    "security_instructions = \"\"\"You are a Security agent reviewing a pull request diff. \n",
    "Identify security vulnerabilities including: SQL injection, command injection, XSS vulnerabilities, hardcoded secrets/credentials, insecure authentication, path traversal, insecure deserialization, improper input validation, and missing error handling that could expose sensitive information.\n",
    "For each issue found, specify the exact lines, severity (1-10), clear fix, and CVE reference if applicable.\"\"\"\n",
    "\n",
    "best_practices_instructions = \"\"\"You are a Best Practices agent reviewing a pull request diff. \n",
    "Identify code quality issues including: unclear variable names, functions exceeding 50 lines, nested complexity over 3 levels, missing docstrings, inconsistent formatting, magic numbers without explanation, violations of DRY principle, unclosed resources (files, database cursors, connections), and missing try-except blocks for error-prone operations.\n",
    "For each issue found, specify the exact lines, severity (1-10), and a clear fix.\"\"\"\n",
    "\n",
    "test_coverage_instructions = \"\"\"You are a Test Coverage agent reviewing a pull request diff. \n",
    "For each new or modified function, suggest test cases covering: normal input cases, edge cases (empty, null, boundary values), error conditions (exceptions, failures, timeouts), and integration scenarios.\n",
    "For each gap found, specify the function name, lines, missing test scenarios, priority (1-10), and whether unit or integration tests are needed.\"\"\"\n",
    "\n",
    "code_analyzer = Agent(\n",
    "    name=\"Code Analyzer\",\n",
    "    instructions=code_analyzer_instructions,\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    output_type=CodeAnalyzerOutput\n",
    ")\n",
    "\n",
    "security_agent = Agent(\n",
    "    name=\"Security Agent\",\n",
    "    instructions=security_instructions,\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    output_type=SecurityOutput\n",
    ")\n",
    "\n",
    "best_practices_agent = Agent(\n",
    "    name=\"Best Practices Agent\",\n",
    "    instructions=best_practices_instructions,\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    output_type=BestPracticesOutput\n",
    ")\n",
    "\n",
    "test_coverage_agent = Agent(\n",
    "    name=\"Test Coverage Agent\",\n",
    "    instructions=test_coverage_instructions,\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    output_type=TestCoverageOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc44cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_security_patterns(code_diff: str, n_results: int = 5) -> str:\n",
    "    chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "    security_collection = chroma_client.get_collection(name=\"security_patterns\")\n",
    "    results = security_collection.query(query_texts=[code_diff], n_results=n_results)\n",
    "    return \"\\n\\n\".join(results['documents'][0]) if results['documents'][0] else \"\"\n",
    "\n",
    "\n",
    "async def run_security_agent_with_rag(code_diff: str):\n",
    "    \"\"\"\n",
    "    Runs security agent with RAG-enhanced context.\n",
    "    \"\"\"\n",
    "    # Get relevant security patterns\n",
    "    patterns = get_relevant_security_patterns(code_diff, n_results=5)\n",
    "    \n",
    "    enhanced_instructions = f\"\"\"You are a Security agent reviewing a pull request diff.\n",
    "\n",
    "{patterns}\n",
    "\n",
    "Based on these patterns and your expertise, identify security vulnerabilities including: SQL injection, command injection, XSS vulnerabilities, hardcoded secrets/credentials, insecure authentication, path traversal, insecure deserialization, improper input validation, and missing error handling that could expose sensitive information.\n",
    "\n",
    "For each issue found, specify the exact lines, severity (1-10), clear fix, and CVE reference if applicable.\"\"\"\n",
    "    \n",
    "    security_agent_rag = Agent(\n",
    "        name=\"Security Agent (RAG)\",\n",
    "        instructions=enhanced_instructions,\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        output_type=SecurityOutput\n",
    "    )\n",
    "    \n",
    "    # Run the agent\n",
    "    result = await Runner.run(security_agent_rag, code_diff)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3566dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING SUBTLE VULNERABILITY\n",
      "============================================================\n",
      "\n",
      "WITH RAG:\n",
      "Found 2 issues\n",
      "- Insecure Deserialization via pickle.load (severity 9)\n",
      "- Path Traversal via Unvalidated Filename Parameter (severity 8)\n",
      "\n",
      "WITHOUT RAG:\n",
      "Found 1 issues\n",
      "- Insecure Deserialization Using pickle.load (severity 9)\n"
     ]
    }
   ],
   "source": [
    "subtle_test = \"\"\"\n",
    "diff --git a/api.py b/api.py\n",
    "+import pickle\n",
    "+\n",
    "+def load_user_data(data_file):\n",
    "+    with open(data_file, 'rb') as f:\n",
    "+        return pickle.load(f)\n",
    "+\n",
    "+def api_endpoint(request):\n",
    "+    filename = request.get('file')\n",
    "+    user_data = load_user_data(filename)\n",
    "+    return user_data\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TESTING SUBTLE VULNERABILITY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# With RAG\n",
    "result_rag = await run_security_agent_with_rag(subtle_test)\n",
    "print(\"\\nWITH RAG:\")\n",
    "print(f\"Found {len(result_rag.final_output.findings)} issues\")\n",
    "for f in result_rag.final_output.findings:\n",
    "    print(f\"- {f.title} (severity {f.severity})\")\n",
    "\n",
    "# Without RAG  \n",
    "result_no_rag = await Runner.run(security_agent, subtle_test)\n",
    "print(\"\\nWITHOUT RAG:\")\n",
    "print(f\"Found {len(result_no_rag.final_output.findings)} issues\")\n",
    "for f in result_no_rag.final_output.findings:\n",
    "    print(f\"- {f.title} (severity {f.severity})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17d6c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def run_all_agents(diff):\n",
    "#     results = await asyncio.gather(\n",
    "#         Runner.run(code_analyzer, diff),\n",
    "#         Runner.run(security_agent, diff),\n",
    "#         Runner.run(best_practices_agent, diff),\n",
    "#         Runner.run(test_coverage_agent, diff)\n",
    "#     )\n",
    "#     return results\n",
    "\n",
    "async def run_all_agents(diff):\n",
    "    # Get RAG context for security agent\n",
    "    security_patterns = get_relevant_security_patterns(diff, n_results=5)\n",
    "    \n",
    "    # Create RAG-enhanced security agent\n",
    "    enhanced_security_instructions = f\"\"\"{security_instructions}\n",
    "\n",
    "RELEVANT SECURITY PATTERNS TO CHECK:\n",
    "{security_patterns}\"\"\"\n",
    "    \n",
    "    security_agent_rag = Agent(\n",
    "        name=\"Security Agent\",\n",
    "        instructions=enhanced_security_instructions,\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        output_type=SecurityOutput\n",
    "    )\n",
    "    \n",
    "    # Run all agents in parallel\n",
    "    results = await asyncio.gather(\n",
    "        Runner.run(code_analyzer, diff),\n",
    "        Runner.run(security_agent_rag, diff),  # Uses RAG\n",
    "        Runner.run(best_practices_agent, diff),\n",
    "        Runner.run(test_coverage_agent, diff)\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6c1bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_findings(\n",
    "    code_result,\n",
    "    security_result, \n",
    "    best_practices_result,\n",
    "    test_coverage_result\n",
    "):\n",
    "    \"\"\"\n",
    "    Organizes all findings by file.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"file.py\": [Finding, Finding, TestGap, ...]\n",
    "        }\n",
    "    \"\"\"\n",
    "    organized = {}\n",
    "    for result in [code_result, security_result,  best_practices_result, test_coverage_result]:\n",
    "        for finding in result.final_output.findings:\n",
    "            file = finding.file\n",
    "            if file not in organized:\n",
    "                organized[file] = []\n",
    "            organized[file].append(finding)\n",
    "        \n",
    "    return organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "421bd51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator_instructions = \"\"\"You are a Code Review Aggregator tasked with creating a deduplicated summary report. Your goal is to merge duplicate findings from multiple agents into a clear, actionable report.\n",
    "\n",
    "You will be provided with findings from multiple agents:\n",
    "<findings>\n",
    "{organized}\n",
    "</findings>\n",
    "\n",
    "When creating the report, follow these guidelines:\n",
    "\n",
    "1. IDENTIFY DUPLICATES: Group findings that describe the same root issue\n",
    "   - Look for overlapping line numbers and similar descriptions\n",
    "   - When multiple agents flag the same problem, merge into one issue\n",
    "   - Use the HIGHEST severity when merging\n",
    "\n",
    "2. PRESERVE INFORMATION: \n",
    "   - Keep agent names: Code Analyzer, Security, Best Practices, Test Coverage\n",
    "   - Include file paths and line numbers\n",
    "   - Maintain the most comprehensive description from merged findings\n",
    "\n",
    "3. CATEGORIZE each issue as:\n",
    "   - Bug: Logic errors, crashes, incorrect behavior  \n",
    "   - Security: Vulnerabilities, unsafe code\n",
    "   - Performance: Inefficient algorithms, resource issues\n",
    "   - Style: Naming, formatting, documentation\n",
    "   - Test Gap: Missing test coverage\n",
    "\n",
    "4. CREATE SUMMARY TABLE with these columns:\n",
    "   | Issue | File | Lines | Severity | Category | Fix | Found By |\n",
    "\n",
    "5. SEPARATE CONCERNS: Test coverage gaps are distinct from code issues\n",
    "\n",
    "Present your report in this format:\n",
    "\n",
    "# Code Review Report\n",
    "\n",
    "## Executive Summary\n",
    "[2-3 sentences highlighting the most critical findings]\n",
    "\n",
    "## Summary of Actions\n",
    "| Issue | File | Lines | Severity | Category | Fix | Found By |\n",
    "|-------|------|-------|----------|----------|-----|----------|\n",
    "[One row per unique issue]\n",
    "\n",
    "**Total Distinct Issues: [count]**\n",
    "\n",
    "CRITICAL REQUIREMENT: \n",
    "- EVERY finding from EVERY agent must appear in the summary table\n",
    "- This includes ALL test coverage gaps reported by the Test Coverage agent\n",
    "- Test gaps should be listed as separate rows (one per function needing tests)\n",
    "- Do NOT omit any findings, especially test coverage gaps\n",
    "- The Total Distinct Issues count must match the number of rows in the table.\"\"\"\n",
    "\n",
    "aggregator = Agent(\n",
    "    name=\"Aggregator\",\n",
    "    instructions=aggregator_instructions,\n",
    "    model=grok_4_fast,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "069ba78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def aggregator_agent(organized):\n",
    "    result = await Runner.run(aggregator, f\"Aggregate these findings into a structured report:\\n\\n{organized}\")\n",
    "    return result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ce4a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def review_code(diff: str, save_output: bool = True) -> str:\n",
    "#     \"\"\"\n",
    "#     Complete code review pipeline.\n",
    "    \n",
    "#     Args:\n",
    "#         diff: The code diff to review\n",
    "        \n",
    "#     Returns:\n",
    "#         Markdown-formatted code review report\n",
    "#     \"\"\"\n",
    "#     results = await run_all_agents(diff)\n",
    "#     code_result, security_result, best_practices_result, test_coverage_result = results    \n",
    "#     organized = organize_findings(code_result, security_result, best_practices_result, test_coverage_result)\n",
    "#     report = await aggregator_agent(organized)\n",
    "    \n",
    "#     if save_output:\n",
    "#         os.makedirs(\"user-data\", exist_ok=True)\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         filepath = f\"user-data/code_review_{timestamp}.md\"\n",
    "#         with open(filepath, \"w\") as f:\n",
    "#             f.write(report)\n",
    "#         print(f\"Report saved to {filepath}\")\n",
    "    \n",
    "#     return report\n",
    "\n",
    "\n",
    "async def review_code(diff: str, save_output: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Complete code review pipeline.\n",
    "    \n",
    "    Args:\n",
    "        diff: The code diff to review\n",
    "        \n",
    "    Returns:\n",
    "        Markdown-formatted code review report\n",
    "    \"\"\"\n",
    "    results = await run_all_agents(diff)\n",
    "    code_result, security_result, best_practices_result, test_coverage_result = results\n",
    "    \n",
    "    # # DEBUG: Print all agent outputs\n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\"CODE ANALYZER RAW OUTPUT:\")\n",
    "    # print(\"=\"*60)\n",
    "    # for finding in code_result.final_output.findings:\n",
    "    #     print(f\"\\nTitle: {finding.title}\")\n",
    "    #     print(f\"Severity: {finding.severity}\")\n",
    "    #     print(f\"Lines: {finding.relevant_lines}\")\n",
    "    #     print(f\"Description: {finding.description[:150]}...\")\n",
    "    # print(\"=\"*60)\n",
    "    \n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\"SECURITY AGENT RAW OUTPUT:\")\n",
    "    # print(\"=\"*60)\n",
    "    # for finding in security_result.final_output.findings:\n",
    "    #     print(f\"\\nTitle: {finding.title}\")\n",
    "    #     print(f\"Severity: {finding.severity}\")\n",
    "    #     print(f\"Lines: {finding.relevant_lines}\")\n",
    "    #     print(f\"Description: {finding.description[:150]}...\")\n",
    "    # print(\"=\"*60)\n",
    "    \n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\"BEST PRACTICES AGENT RAW OUTPUT:\")\n",
    "    # print(\"=\"*60)\n",
    "    # for finding in best_practices_result.final_output.findings:\n",
    "    #     print(f\"\\nTitle: {finding.title}\")\n",
    "    #     print(f\"Severity: {finding.severity}\")\n",
    "    #     print(f\"Lines: {finding.relevant_lines}\")\n",
    "    #     print(f\"Description: {finding.description[:150]}...\")\n",
    "    # print(\"=\"*60)\n",
    "    \n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\"TEST COVERAGE AGENT RAW OUTPUT:\")\n",
    "    # print(\"=\"*60)\n",
    "    # for gap in test_coverage_result.final_output.findings:\n",
    "    #     print(f\"\\nFunction: {gap.function_name}\")\n",
    "    #     print(f\"Priority: {gap.priority}\")\n",
    "    #     print(f\"Lines: {gap.lines}\")\n",
    "    #     print(f\"Missing scenarios: {gap.missing_scenarios}\")\n",
    "    # print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    organized = organize_findings(code_result, security_result, best_practices_result, test_coverage_result)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CALLING AGGREGATOR...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    report = await aggregator_agent(organized)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AGGREGATOR OUTPUT:\")\n",
    "    print(\"=\"*60)\n",
    "    print(report)\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    if save_output:\n",
    "        os.makedirs(\"user-data\", exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filepath = f\"user-data/code_review_{timestamp}.md\"\n",
    "        with open(filepath, \"w\") as f:\n",
    "            f.write(report)\n",
    "        print(f\"Report saved to {filepath}\")\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "211922ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CODE ANALYZER RAW OUTPUT:\n",
      "============================================================\n",
      "\n",
      "Title: SQL Injection Vulnerability\n",
      "Severity: 9\n",
      "Lines: [8, 9, 10]\n",
      "Description: The authenticate method constructs SQL queries by directly concatenating user inputs (username and password) into the query string. This allows an att...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SECURITY AGENT RAW OUTPUT:\n",
      "============================================================\n",
      "\n",
      "Title: SQL Injection in authenticate method\n",
      "Severity: 9\n",
      "Lines: [7, 8, 9, 10]\n",
      "Description: The authenticate method constructs an SQL query by directly concatenating user inputs (username and password) into the query string. This allows an at...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "BEST PRACTICES AGENT RAW OUTPUT:\n",
      "============================================================\n",
      "\n",
      "Title: SQL Injection Vulnerability\n",
      "Severity: 9\n",
      "Lines: [7, 8, 9]\n",
      "Description: The authenticate method builds the SQL query by concatenating user inputs directly into the query string. This approach is vulnerable to SQL injection...\n",
      "\n",
      "Title: Missing Cursor Closure\n",
      "Severity: 5\n",
      "Lines: [8, 9]\n",
      "Description: The database cursor created in the authenticate method is not explicitly closed, which can lead to resource leaks....\n",
      "\n",
      "Title: No Exception Handling for Database Operations\n",
      "Severity: 6\n",
      "Lines: [7, 8, 9, 10]\n",
      "Description: The authenticate method does not include try-except blocks around database operations, making it prone to unhandled exceptions that could crash the ap...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TEST COVERAGE AGENT RAW OUTPUT:\n",
      "============================================================\n",
      "\n",
      "Function: authenticate\n",
      "Priority: 9\n",
      "Lines: [7, 8, 9, 10, 11, 12]\n",
      "Missing scenarios: ['normal case: valid username and password', 'edge case: empty username and/or password', 'edge case: SQL injection attempt in username or password', 'error handling: database connection failure or query execution error', 'integration: interaction with actual database and user records']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "CALLING AGGREGATOR...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AGGREGATOR OUTPUT:\n",
      "============================================================\n",
      "# Code Review Report\n",
      "\n",
      "## Executive Summary\n",
      "The most critical issue identified is a severe SQL injection vulnerability in the `authenticate` method of `user_auth.py`, flagged by multiple agents, which could allow attackers to compromise the database or bypass authentication. Additional concerns include missing cursor closure leading to potential resource leaks and lack of exception handling around database operations, both increasing the risk of application instability. Test coverage is notably deficient for the `authenticate` function, lacking scenarios for normal use, edges, security attempts, errors, and integration.\n",
      "\n",
      "## Summary of Actions\n",
      "| Issue | File | Lines | Severity | Category | Fix | Found By |\n",
      "|-------|------|-------|----------|----------|-----|----------|\n",
      "| SQL Injection Vulnerability in authenticate method | user_auth.py | 7-10 | 9 | Security | Use parameterized queries with placeholders to safely insert user input values into the SQL query, preventing injection attacks. For example, use `query = \"SELECT * FROM users WHERE username=? AND password=?\"` and pass `(username, password)` as parameters to `cursor.execute()`. | Code Analyzer, Security, Best Practices |\n",
      "| Missing Cursor Closure | user_auth.py | 8-9 | 5 | Performance | Use a context manager (with statement) when creating the cursor to ensure it is closed automatically, e.g., `with self.db.cursor() as cursor: cursor.execute(query, (username, password)) ...`. | Best Practices |\n",
      "| No Exception Handling for Database Operations | user_auth.py | 7-10 | 6 | Bug | Add try-except blocks to catch database exceptions and handle them gracefully, for example: `try: ... except sqlite3.DatabaseError as e: # Handle or log the error return False`. | Best Practices |\n",
      "| Missing tests for authenticate function | user_auth.py | 7-12 | 9 | Test Gap | Unit tests with mocking for query execution and integration tests with a test database, covering: normal case (valid username and password), edge cases (empty username/password, SQL injection attempts), error handling (database connection failure or query execution error), and integration with actual database and user records. | Test Coverage |\n",
      "\n",
      "**Total Distinct Issues: 4**\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff_file = Path(\"test-cases/01_sql_injection.diff\")\n",
    "diff_content = diff_file.read_text()\n",
    "\n",
    "report = await review_code(diff_content, save_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a73ded2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_instructions = \"\"\"You are an evaluation judge for code review systems comparing expected findings (ground truth) against actual findings.\n",
    "\n",
    "CRITICAL MATCHING RULES:\n",
    "1. Each actual finding can match AT MOST ONE expected finding\n",
    "2. Each expected finding can match AT MOST ONE actual finding\n",
    "3. Once an actual finding is matched, it CANNOT be used again\n",
    "4. Only match within same category (bugs ≠ test gaps)\n",
    "\n",
    "PROCESS:\n",
    "1. Count total_actual from \"Total Distinct Issues: X\" in report\n",
    "2. For EACH expected finding:\n",
    "   - Find the BEST matching actual finding that hasn't been used yet\n",
    "   - If good match exists: mark as matched=True, record which actual finding\n",
    "   - If no match: mark as matched=False\n",
    "   - NEVER reuse an actual finding for multiple expected findings\n",
    "\n",
    "A match means the same type of issue was identified, even if worded differently.\n",
    "\"\"\"\n",
    "\n",
    "class MatchedFinding(BaseModel):\n",
    "    expected: str = Field(description=\"the expected finding text\")\n",
    "    matched: bool = Field(description=\"true if the expected finding is present, else false\")\n",
    "    actual_finding: Optional[str] = Field(default=None, description=\"the matching text from report (if matched)\")\n",
    "\n",
    "class EvaluationResult(BaseModel):\n",
    "    matched_findings: list[MatchedFinding]\n",
    "    total_expected: int = Field(description=\"Total number of expected findings from ground truth\")\n",
    "    total_actual: int = Field(description=\"Count of distinct issues in the report's summary section\")\n",
    "    # matches: int = Field(description=\"Number of expected findings successfully matched\")\n",
    "    \n",
    "    def model_post_init(self, __context):\n",
    "        # Calculate matches from the list\n",
    "        matches = sum(1 for mf in self.matched_findings if mf.matched)\n",
    "        \n",
    "        # Check for duplicate actual findings\n",
    "        actual_findings_used = [\n",
    "            mf.actual_finding for mf in self.matched_findings \n",
    "            if mf.matched and mf.actual_finding\n",
    "        ]\n",
    "        unique_actuals = len(set(actual_findings_used))\n",
    "        \n",
    "        if matches > unique_actuals:\n",
    "            print(f\"ERROR: {matches} matches but only {unique_actuals} unique actual findings used!\")\n",
    "            print(\"The judge matched the same actual finding multiple times.\")\n",
    "        \n",
    "        if matches > self.total_actual:\n",
    "            print(f\"WARNING: Matches ({matches}) > Total Actual ({self.total_actual})\")\n",
    "\n",
    "\n",
    "\n",
    "async def evaluate_report(report: str, ground_truth_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fixed evaluation function with proper counting.\n",
    "    \"\"\"\n",
    "    \n",
    "    judge_agent = Agent(\n",
    "        name=\"Evaluation Judge\",\n",
    "        instructions=judge_instructions,\n",
    "        model=\"gpt-5.1\",\n",
    "        output_type=EvaluationResult\n",
    "    )\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "GROUND TRUTH (expected findings):\n",
    "{ground_truth_content}\n",
    "\n",
    "ACTUAL REPORT (what the system found):\n",
    "{report}\n",
    "\n",
    "For each expected finding, determine if it matches any actual finding.\n",
    "Output matched_findings list, total_expected, and total_actual.\n",
    "\"\"\"\n",
    "    \n",
    "    result = await Runner.run(judge_agent, prompt)\n",
    "    eval_result = result.final_output\n",
    "    \n",
    "    # Calculate matches from the actual data - don't trust LLM counting\n",
    "    matches = sum(1 for mf in eval_result.matched_findings if mf.matched)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    recall = matches / eval_result.total_expected if eval_result.total_expected > 0 else 0\n",
    "    precision = matches / eval_result.total_actual if eval_result.total_actual > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1,\n",
    "        \"matches\": matches,\n",
    "        \"total_expected\": eval_result.total_expected,\n",
    "        \"total_actual\": eval_result.total_actual,\n",
    "        \"details\": eval_result.matched_findings\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c9aa656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CALLING AGGREGATOR...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AGGREGATOR OUTPUT:\n",
      "============================================================\n",
      "# Code Review Report\n",
      "\n",
      "## Executive Summary\n",
      "The most critical issue is a high-severity SQL injection vulnerability in the `authenticate` method of `user_auth.py`, flagged by multiple agents, which could allow attackers to bypass authentication or access sensitive data; it must be addressed immediately using parameterized queries. Additional bugs include missing exception handling that risks application crashes, while best practices highlight resource leaks from unclosed cursors and lack of documentation. Test coverage for the `authenticate` function is severely lacking, with no tests for normal, edge, security, and error scenarios, requiring comprehensive unit and integration tests.\n",
      "\n",
      "## Summary of Actions\n",
      "| Issue | File | Lines | Severity | Category | Fix | Found By |\n",
      "|-------|------|-------|----------|----------|-----|----------|\n",
      "| SQL Injection Vulnerability | user_auth.py | 7-12 | 9 | Security | Use parameterized queries or prepared statements to safely pass user inputs to the SQL query, e.g., replace query construction with `query = \"SELECT * FROM users WHERE username=? AND password=?\"` and call `cursor.execute(query, (username, password))`. | Code Analyzer, Security, Best Practices |\n",
      "| Missing Exception Handling for Database Operations | user_auth.py | 7-11 | 6 | Bug | Wrap database operations inside try-except blocks to catch potential sqlite3.DatabaseError or other exceptions and handle them gracefully. | Code Analyzer |\n",
      "| Unclosed Cursor Resource | user_auth.py | 9-10 | 5 | Performance | Use a context manager (with statement) for the cursor or explicitly close the cursor after use to ensure resources are properly released. | Best Practices |\n",
      "| Missing Docstring for Method | user_auth.py | 7,12 | 3 | Style | Add a docstring to the authenticate method explaining what it does, its input parameters, and what it returns. | Best Practices |\n",
      "| Test Coverage Gap in authenticate | user_auth.py | 7-11 | 9 | Test Gap | Add unit tests for function behavior including mocking database cursor (covering normal case: valid username and password returns True; edge case: empty username and/or password; edge case: SQL injection attempt in username or password; error handling: database connection failure; error handling: exceptions from malformed SQL query) and integration tests for full authentication flow with real database and user data. | Test Coverage |\n",
      "\n",
      "**Total Distinct Issues: 5**\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "JUDGE OUTPUT:\n",
      "============================================================\n",
      "total_expected: 5\n",
      "total_actual: 5\n",
      "matches: 5\n",
      "\n",
      "matched_findings:\n",
      "\n",
      "  Expected: SQL injection vulnerability in authenticate method due to string concatenation of user inputs\n",
      "  Matched: True\n",
      "  Actual: SQL Injection Vulnerability | user_auth.py | 7-12 | 9 | Security | Use parameterized queries or prep...\n",
      "\n",
      "  Expected: Missing docstring for authenticate method\n",
      "  Matched: True\n",
      "  Actual: Missing Docstring for Method | user_auth.py | 7,12 | 3 | Style | Add a docstring to the authenticate...\n",
      "\n",
      "  Expected: No error handling for database query failures\n",
      "  Matched: True\n",
      "  Actual: Missing Exception Handling for Database Operations | user_auth.py | 7-11 | 6 | Bug | Wrap database o...\n",
      "\n",
      "  Expected: Database cursor not explicitly closed (best practice)\n",
      "  Matched: True\n",
      "  Actual: Unclosed Cursor Resource | user_auth.py | 9-10 | 5 | Performance | Use a context manager (with state...\n",
      "\n",
      "  Expected: Missing test coverage for authenticate method\n",
      "  Matched: True\n",
      "  Actual: Test Coverage Gap in authenticate | user_auth.py | 7-11 | 9 | Test Gap | Add unit tests for function...\n",
      "\n",
      "============================================================\n",
      "CALCULATED METRICS:\n",
      "============================================================\n",
      "Recall: 1.00\n",
      "Precision: 1.00\n",
      "F1 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Run test 2\n",
    "test_dir = Path(\"test-cases\")\n",
    "diff_file = test_dir / \"01_sql_injection.diff\"\n",
    "\n",
    "# Load files\n",
    "diff_content = diff_file.read_text()\n",
    "expected_file = diff_file.with_name(\"01_sql_injection_expected.json\")\n",
    "ground_truth_content = expected_file.read_text()\n",
    "\n",
    "# Run review WITH saving\n",
    "report = await review_code(diff_content, save_output=False)\n",
    "\n",
    "# Evaluate\n",
    "eval_result = await evaluate_report(report, ground_truth_content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"JUDGE OUTPUT:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"total_expected: {eval_result['total_expected']}\")\n",
    "print(f\"total_actual: {eval_result['total_actual']}\")\n",
    "print(f\"matches: {eval_result['matches']}\")\n",
    "print(f\"\\nmatched_findings:\")\n",
    "for mf in eval_result['details']:\n",
    "    print(f\"\\n  Expected: {mf.expected}\")\n",
    "    print(f\"  Matched: {mf.matched}\")\n",
    "    if mf.actual_finding:\n",
    "        print(f\"  Actual: {mf.actual_finding[:100]}...\")  # truncate if long\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CALCULATED METRICS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Recall: {eval_result['recall']:.2f}\")\n",
    "print(f\"Precision: {eval_result['precision']:.2f}\")\n",
    "print(f\"F1 Score: {eval_result['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a2694f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the same test twice to check consistency\n",
    "# test_dir = Path(\"test-cases\")\n",
    "# diff_file = test_dir / \"04_multi_file_security.diff\"\n",
    "\n",
    "# # Load files\n",
    "# diff_content = diff_file.read_text()\n",
    "# expected_file = test_dir / \"04_multi_file_security_expected.json\"\n",
    "# ground_truth_content = expected_file.read_text()\n",
    "\n",
    "# # Run twice\n",
    "# for i in range(2):\n",
    "#     print(f\"\\n=== RUN {i+1} ===\")\n",
    "    \n",
    "#     # Run review\n",
    "#     report = await review_code(diff_content, save_output=False)\n",
    "    \n",
    "#     # Evaluate\n",
    "#     eval_result = await evaluate_report(report, ground_truth_content)\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*60)\n",
    "#     print(\"JUDGE OUTPUT:\")\n",
    "#     print(\"=\"*60)\n",
    "#     print(f\"total_expected: {eval_result['total_expected']}\")\n",
    "#     print(f\"total_actual: {eval_result['total_actual']}\")\n",
    "#     print(f\"matches: {eval_result['matches']}\")\n",
    "#     print(f\"\\nmatched_findings:\")\n",
    "#     for mf in eval_result['details']:\n",
    "#         print(f\"\\n  Expected: {mf.expected}\")\n",
    "#         print(f\"  Matched: {mf.matched}\")\n",
    "#         if mf.actual_finding:\n",
    "#             print(f\"  Actual: {mf.actual_finding[:100]}...\")  # truncate if long\n",
    "\n",
    "#     print(\"\\n\" + \"=\"*60)\n",
    "#     print(\"CALCULATED METRICS:\")\n",
    "#     print(\"=\"*60)\n",
    "#     print(f\"Recall: {eval_result['recall']:.2f}\")\n",
    "#     print(f\"Precision: {eval_result['precision']:.2f}\")\n",
    "#     print(f\"F1 Score: {eval_result['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b57fa37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING: 01_sql_injection\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "CALLING AGGREGATOR...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AGGREGATOR OUTPUT:\n",
      "============================================================\n",
      "# Code Review Report\n",
      "\n",
      "## Executive Summary\n",
      "The most critical issue identified is a severe SQL injection vulnerability in the `authenticate` method of `user_auth.py`, flagged by multiple agents, which could allow attackers to bypass authentication or manipulate the database. Additional high-severity concerns include storing plaintext passwords and missing exception handling for database operations, both posing significant security and reliability risks. The file also has resource leaks, style issues, and comprehensive test coverage gaps that need addressing to ensure robust code quality.\n",
      "\n",
      "## Summary of Actions\n",
      "| Issue | File | Lines | Severity | Category | Fix | Found By |\n",
      "|-------|------|-------|----------|----------|-----|----------|\n",
      "| SQL Injection Vulnerability: The 'authenticate' method constructs the SQL query by directly concatenating user input 'username' and 'password' without sanitation or parameterization. This allows for SQL injection attacks where an attacker can manipulate the query to bypass authentication or access unauthorized data. | user_auth.py | 7-18 | 9 | Security | Use parameterized queries with placeholders to safely pass user inputs, for example: query = \"SELECT * FROM users WHERE username=? AND password=?\" and then execute with parameters (username, password). | Code Analyzer, Security, Best Practices |\n",
      "| Resource Leak: Unclosed Cursor: The 'authenticate' method creates a cursor but does not close it after use. This can lead to resource leaks, especially if 'authenticate' is called frequently. | user_auth.py | 8-12 | 5 | Bug | Use a context manager for the cursor: 'with self.db.cursor() as cursor:' if supported, or explicitly close the cursor after use: cursor.close(). | Code Analyzer, Best Practices |\n",
      "| Storing Plaintext Passwords: The method checks passwords by comparing raw strings from the database, suggesting that passwords are stored in plaintext. This is insecure and violates best practices for password handling. | user_auth.py | 7-12 | 8 | Security | Store only hashed passwords using a strong hashing algorithm (e.g., bcrypt). During authentication, hash the input password and compare it to the stored hash. | Code Analyzer |\n",
      "| Missing docstring in method: The authenticate method is missing a docstring that describes its behavior, parameters, and return value. | user_auth.py | 7 | 3 | Style | Add a docstring to the authenticate method, explaining its purpose, parameters (username, password), and return value (True if authentication succeeds, False otherwise). | Best Practices |\n",
      "| Missing exception handling for database operations: The authenticate method does not handle exceptions that may arise during database access, which can cause the program to crash unexpectedly. | user_auth.py | 7-11 | 6 | Bug | Wrap database operations in try-except blocks to catch and handle database errors gracefully, possibly logging the error and returning False or raising a custom exception. | Best Practices |\n",
      "| Test Gap for authenticate: Missing scenarios including normal case (valid username and password), edge cases (empty username/password, SQL injection attempts), error handling (database connection/query failure), and integration with multiple users. | user_auth.py | 7-11 | 10 | Test Gap | Unit tests with mocking of the database connection and cursor; integration tests with a test database. | Test Coverage |\n",
      "\n",
      "**Total Distinct Issues: 6**\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "JUDGE OUTPUT:\n",
      "============================================================\n",
      "total_expected: 5\n",
      "total_actual: 6\n",
      "matches: 5\n",
      "\n",
      "matched_findings:\n",
      "\n",
      "  Expected: SQL injection vulnerability in authenticate method due to string concatenation of user inputs\n",
      "  Matched: True\n",
      "  Actual: SQL Injection Vulnerability: The 'authenticate' method constructs the SQL query by directly concaten...\n",
      "\n",
      "  Expected: Missing docstring for authenticate method\n",
      "  Matched: True\n",
      "  Actual: Missing docstring in method: The authenticate method is missing a docstring that describes its behav...\n",
      "\n",
      "  Expected: No error handling for database query failures\n",
      "  Matched: True\n",
      "  Actual: Missing exception handling for database operations: The authenticate method does not handle exceptio...\n",
      "\n",
      "  Expected: Database cursor not explicitly closed (best practice)\n",
      "  Matched: True\n",
      "  Actual: Resource Leak: Unclosed Cursor: The 'authenticate' method creates a cursor but does not close it aft...\n",
      "\n",
      "  Expected: Missing test coverage for authenticate method\n",
      "  Matched: True\n",
      "  Actual: Test Gap for authenticate: Missing scenarios including normal case (valid username and password), ed...\n",
      "\n",
      "============================================================\n",
      "CALCULATED METRICS:\n",
      "============================================================\n",
      "Recall: 1.00\n",
      "Precision: 0.83\n",
      "F1 Score: 0.91\n",
      "Status: ✗ FAILED\n",
      "\n",
      "============================================================\n",
      "TESTING: 02_logic_bug\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "CALLING AGGREGATOR...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AGGREGATOR OUTPUT:\n",
      "============================================================\n",
      "# Code Review Report\n",
      "\n",
      "## Executive Summary\n",
      "The code in inventory.py contains a critical off-by-one error in the find_item method that can lead to IndexError crashes and potential security implications like denial of service or information leakage. Additional issues include inefficient implementation of get_last_n_items and missing docstrings, which impact performance and maintainability. Test coverage is notably lacking for both get_last_n_items and find_item, with high-priority gaps in edge cases and error handling that could miss detecting the identified bug.\n",
      "\n",
      "## Summary of Actions\n",
      "| Issue | File | Lines | Severity | Category | Fix | Found By |\n",
      "|-------|------|-------|----------|----------|-----|----------|\n",
      "| Off-by-one error in find_item method causing IndexError | inventory.py | [11-18] | 7 | Bug | Change the loop to range(len(self.items)) or iterate directly over self.items (e.g., for item in self.items: if item.id == item_id: return item) to prevent out-of-bounds access; this avoids unhandled exceptions that could reveal sensitive information or cause denial of service | Code Analyzer, Security, Best Practices |\n",
      "| Inefficient get_last_n_items implementation | inventory.py | [5-10] | 3 | Performance | Replace the method body with return self.items[-n:] to use efficient list slicing | Best Practices |\n",
      "| Missing docstrings in class and methods | inventory.py | [1,4,6,11] | 4 | Style | Add docstrings to the Inventory class and all methods, explaining purpose, parameters, and behavior | Best Practices |\n",
      "| Missing tests for get_last_n_items (scenarios: normal n < length; n=0; n > length; n negative; empty list; non-integer n) | inventory.py | [5,14] | 7 | Test Gap | Add unit tests covering all listed missing scenarios | Test Coverage |\n",
      "| Missing tests for find_item (scenarios: item present; item absent; empty list; item_id=None; index out of range due to loop bounds) | inventory.py | [15,23] | 9 | Test Gap | Add unit tests covering all listed missing scenarios | Test Coverage |\n",
      "\n",
      "**Total Distinct Issues: 5**\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "JUDGE OUTPUT:\n",
      "============================================================\n",
      "total_expected: 6\n",
      "total_actual: 5\n",
      "matches: 5\n",
      "\n",
      "matched_findings:\n",
      "\n",
      "  Expected: Off-by-one error in find_item causing IndexError - loop iterates beyond list bounds\n",
      "  Matched: True\n",
      "  Actual: Off-by-one error in find_item method causing IndexError...\n",
      "\n",
      "  Expected: Inefficient implementation of get_last_n_items - should use list slicing\n",
      "  Matched: True\n",
      "  Actual: Inefficient get_last_n_items implementation...\n",
      "\n",
      "  Expected: No error handling for edge cases in get_last_n_items (n=0, n>length, negative n, empty list)\n",
      "  Matched: False\n",
      "\n",
      "  Expected: Missing docstrings for both methods\n",
      "  Matched: True\n",
      "  Actual: Missing docstrings in class and methods...\n",
      "\n",
      "  Expected: Missing test coverage for get_last_n_items\n",
      "  Matched: True\n",
      "  Actual: Missing tests for get_last_n_items (scenarios: normal n < length; n=0; n > length; n negative; empty...\n",
      "\n",
      "  Expected: Missing test coverage for find_item\n",
      "  Matched: True\n",
      "  Actual: Missing tests for find_item (scenarios: item present; item absent; empty list; item_id=None; index o...\n",
      "\n",
      "============================================================\n",
      "CALCULATED METRICS:\n",
      "============================================================\n",
      "Recall: 0.83\n",
      "Precision: 1.00\n",
      "F1 Score: 0.91\n",
      "Status: ✓ PASSED\n",
      "\n",
      "============================================================\n",
      "TESTING: 03_code_quality\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "CALLING AGGREGATOR...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AGGREGATOR OUTPUT:\n",
      "============================================================\n",
      "# Code Review Report\n",
      "\n",
      "## Executive Summary\n",
      "The most critical issue is the excessive nesting complexity in the `calculate` method of `calculator.py`, which severely impacts readability and maintainability, flagged at severity 7 by both Code Analyzer and Best Practices agents. Additionally, the `calculate` method lacks comprehensive test coverage for key scenarios like boundary values and error handling, with priority 8 from the Test Coverage agent. Other notable concerns include inconsistent input validation logic and missing docstrings, contributing to overall code quality issues, while the `process` method appears unused and under-tested.\n",
      "\n",
      "## Summary of Actions\n",
      "| Issue | File | Lines | Severity | Category | Fix | Found By |\n",
      "|-------|------|-------|----------|----------|-----|----------|\n",
      "| Excessive nested complexity in calculate method | calculator.py | [3-25] | 7 | Style | Refactor the calculate method to reduce nesting by using guard clauses or combined conditions. For example, return 0 early if any of a,b,c,d,e is not greater than 0 before performing calculations. Replace nested if statements with a single compound condition, e.g. if all(x > 0 for x in (a,b,c,d,e)): ... else: return 0. | Code Analyzer, Best Practices |\n",
      "| Inconsistent Handling of Zero or Negative Inputs | calculator.py | [3, 24] | 5 | Bug | Add input validation with clear error messages or exceptions for invalid inputs. Alternatively, decide on meaningful behavior for zero or negative values rather than silently returning 0. | Code Analyzer |\n",
      "| Unused process Method | calculator.py | [26, 27] | 2 | Bug | Implement desired processing logic or remove this method if not needed to avoid confusion. | Code Analyzer |\n",
      "| Missing docstrings for class and methods | calculator.py | [1, 3, 24] | 4 | Style | Add descriptive docstrings to the Calculator class and both its methods explaining their purpose, parameters, and return values. | Best Practices |\n",
      "| Use of magic numbers without explanations | calculator.py | [10, 11, 12, 13] | 5 | Style | Define these numeric constants as named variables or class attributes with descriptive names to clarify their meaning and facilitate changes in the future. | Best Practices |\n",
      "| Test coverage gap for calculate function | calculator.py | [2, 23] | 8 | Test Gap | Write unit tests covering: normal input with all positive values, each parameter exactly zero or negative (boundary values), parameters as zero to test the early returns, very large values to check for overflow or performance, non-integer and non-float inputs (type validation), error handling if inputs are not numbers, confirm that each conditional branch returns 0 appropriately. | Test Coverage |\n",
      "| Test coverage gap for process function | calculator.py | [24, 25] | 4 | Test Gap | Write unit and integration tests covering: normal input with typical data, input as None or empty data, non-standard input types, check that the function returns the input unchanged, integration test to see usage in a pipeline. | Test Coverage |\n",
      "\n",
      "**Total Distinct Issues: 7**\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "JUDGE OUTPUT:\n",
      "============================================================\n",
      "total_expected: 9\n",
      "total_actual: 7\n",
      "matches: 7\n",
      "\n",
      "matched_findings:\n",
      "\n",
      "  Expected: Excessive nesting depth in calculate method (5 levels deep)\n",
      "  Matched: True\n",
      "  Actual: Excessive nested complexity in calculate method...\n",
      "\n",
      "  Expected: Magic numbers without explanation (1.15, 0.95, 1.08, 1.12, 0.88)\n",
      "  Matched: True\n",
      "  Actual: Use of magic numbers without explanations...\n",
      "\n",
      "  Expected: Unclear variable names (a, b, c, d, e, x, y, z)\n",
      "  Matched: False\n",
      "\n",
      "  Expected: Missing docstrings for class and both methods\n",
      "  Matched: True\n",
      "  Actual: Missing docstrings for class and methods...\n",
      "\n",
      "  Expected: calculate method returns 0 for any negative input without clear business logic justification\n",
      "  Matched: True\n",
      "  Actual: Inconsistent Handling of Zero or Negative Inputs...\n",
      "\n",
      "  Expected: Repeated return 0 statements could be simplified\n",
      "  Matched: False\n",
      "\n",
      "  Expected: process method does nothing useful and should be removed or implemented\n",
      "  Matched: True\n",
      "  Actual: Unused process Method...\n",
      "\n",
      "  Expected: Missing test coverage for calculate method including positive inputs, negative inputs, edge cases, and validation of magic number calculations\n",
      "  Matched: True\n",
      "  Actual: Test coverage gap for calculate function...\n",
      "\n",
      "  Expected: Missing test coverage or clarification for process method purpose\n",
      "  Matched: True\n",
      "  Actual: Test coverage gap for process function...\n",
      "\n",
      "============================================================\n",
      "CALCULATED METRICS:\n",
      "============================================================\n",
      "Recall: 0.78\n",
      "Precision: 1.00\n",
      "F1 Score: 0.88\n",
      "Status: ✗ FAILED\n",
      "\n",
      "============================================================\n",
      "TESTING: 04_multi_file_security\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "CALLING AGGREGATOR...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AGGREGATOR OUTPUT:\n",
      "============================================================\n",
      "# Code Review Report\n",
      "\n",
      "## Executive Summary\n",
      "The code exhibits multiple high-severity security vulnerabilities, including command injection, insecure deserialization via pickle, and path traversal attacks, which could lead to arbitrary code execution or unauthorized file access. Additional issues include missing error handling, poor coding practices like hardcoded secrets and inconsistent path construction, and significant test coverage gaps for key functions handling user input and file operations. Prioritizing fixes for security issues is essential to prevent exploitation, followed by adding comprehensive tests to validate behavior.\n",
      "\n",
      "## Summary of Actions\n",
      "\n",
      "| Issue | File | Lines | Severity | Category | Fix | Found By |\n",
      "|-------|------|-------|----------|----------|-----|----------|\n",
      "| Hardcoded Sensitive Information | api_handler.py | 4-7 | 9 | Security | Move API keys and secrets to environment variables or secure vault and load them securely at runtime; avoid storing secrets directly in source code to prevent exposure through version control or leaks. | Code Analyzer, Security, Best Practices |\n",
      "| Command Injection Vulnerability | api_handler.py | 9-10 | 10 | Security | Sanitize user input before using in shell commands or use subprocess with argument list to avoid shell interpretation; avoid os.system with raw user input and use subprocess.run() with lists, validating or escaping input carefully. | Code Analyzer, Security, Best Practices |\n",
      "| Untrusted Pickle Loading (Arbitrary Code Execution Risk) | api_handler.py | 12-14 | 10 | Security | Avoid using pickle to load untrusted input; consider safer formats like JSON or use pickle only on trusted data with validation; prefer safer serialization formats like JSON or secure deserialization libraries enforcing type restrictions. | Code Analyzer, Security |\n",
      "| Missing Try-Except for File and Pickle Operations | api_handler.py | 13-14 | 7 | Bug | Wrap file opening and pickle loading operations in try-except blocks to handle IOErrors and pickle.UnpicklingError exceptions gracefully, including for FileHandler operations. | Best Practices |\n",
      "| Missing Docstrings on Classes and Methods | api_handler.py | 2,5,8,11 | 4 | Style | Add appropriate docstrings to classes (APIHandler, FileHandler) and all methods describing their purpose, parameters, and return values. | Best Practices |\n",
      "| Missing Tests for execute_command | api_handler.py | 7-10 | 8 | Test Gap | Implement unit test with mocking of os.system covering: normal case (valid command string), edge cases (empty string, special shell characters, very long input), error conditions (command injection attempts), and integration with OS shell environment. | Test Coverage |\n",
      "| Missing Tests for load_data | api_handler.py | 11-14 | 9 | Test Gap | Implement unit test with mocked open and pickle.load covering: normal case (valid pickle file), error conditions (file missing, invalid format, permission denied), edge case (empty file), and integration with subsequent processing. | Test Coverage |\n",
      "| Path Traversal in read_user_file | file_handler.py | 4-8 | 8 | Security | Sanitize filename input to prevent directory traversal by restricting allowed characters or use os.path methods to ensure the final path is within the allowed directory; reject or normalize paths with '..' or absolute components and use safe APIs to restrict access. | Code Analyzer, Security |\n",
      "| Path Traversal in delete_file | file_handler.py | 8-14 | 9 | Security | Validate and sanitize filename input to prevent directory traversal; ensure only intended files can be deleted by checking resolved paths, using OS-level restrictions, and avoiding raw user input concatenation; consider whitelisting allowed filenames. | Code Analyzer, Security |\n",
      "| Imported Module Inside Method | file_handler.py | 10 | 3 | Style | Move all imports (e.g., 'import os') to the top of the file as per Python conventions to improve readability. | Best Practices |\n",
      "| Inconsistent File Path Handling | file_handler.py | 4,11 | 4 | Style | Use os.path.join() to construct file paths to be OS-independent and safer, avoiding string concatenation which can cause cross-platform issues. | Best Practices |\n",
      "| Missing Tests for read_user_file | file_handler.py | 2-6 | 7 | Test Gap | Implement unit test with mocking open and file system calls covering: normal case (existing readable file), error conditions (file missing, permission denied, path traversal attempts), edge cases (empty file, empty filename). | Test Coverage |\n",
      "| Missing Tests for delete_file | file_handler.py | 7-10 | 8 | Test Gap | Implement unit test with mocking os.remove and file system calls covering: normal case (existing file), error conditions (file missing, permission denied, path traversal attempts), edge cases (empty filename), and integration with system state changes. | Test Coverage |\n",
      "\n",
      "**Total Distinct Issues: 13**\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "JUDGE OUTPUT:\n",
      "============================================================\n",
      "total_expected: 15\n",
      "total_actual: 13\n",
      "matches: 10\n",
      "\n",
      "matched_findings:\n",
      "\n",
      "  Expected: Hardcoded API key in api_handler.py\n",
      "  Matched: True\n",
      "  Actual: Hardcoded Sensitive Information | api_handler.py | 4-7 | 9 | Security...\n",
      "\n",
      "  Expected: Hardcoded secret password in api_handler.py\n",
      "  Matched: False\n",
      "\n",
      "  Expected: Command injection vulnerability in execute_command via os.system with unsanitized user input\n",
      "  Matched: True\n",
      "  Actual: Command Injection Vulnerability | api_handler.py | 9-10 | 10 | Security...\n",
      "\n",
      "  Expected: Insecure deserialization using pickle.load in load_data which can execute arbitrary code\n",
      "  Matched: True\n",
      "  Actual: Untrusted Pickle Loading (Arbitrary Code Execution Risk) | api_handler.py | 12-14 | 10 | Security...\n",
      "\n",
      "  Expected: Path traversal vulnerability in read_user_file allowing access to arbitrary files\n",
      "  Matched: True\n",
      "  Actual: Path Traversal in read_user_file | file_handler.py | 4-8 | 8 | Security...\n",
      "\n",
      "  Expected: Path traversal vulnerability in delete_file allowing deletion of arbitrary files\n",
      "  Matched: True\n",
      "  Actual: Path Traversal in delete_file | file_handler.py | 8-14 | 9 | Security...\n",
      "\n",
      "  Expected: No input validation in execute_command\n",
      "  Matched: False\n",
      "\n",
      "  Expected: No path sanitization in read_user_file and delete_file\n",
      "  Matched: False\n",
      "\n",
      "  Expected: Missing error handling in all methods\n",
      "  Matched: False\n",
      "\n",
      "  Expected: Missing docstrings for both classes and all methods\n",
      "  Matched: True\n",
      "  Actual: Missing Docstrings on Classes and Methods | api_handler.py | 2,5,8,11 | 4 | Style...\n",
      "\n",
      "  Expected: Missing error handling in delete_file for file not found or permission errors\n",
      "  Matched: False\n",
      "\n",
      "  Expected: Missing test coverage for execute_command including command injection attempts\n",
      "  Matched: True\n",
      "  Actual: Missing Tests for execute_command | api_handler.py | 7-10 | 8 | Test Gap...\n",
      "\n",
      "  Expected: Missing test coverage for load_data including malicious pickle payloads\n",
      "  Matched: True\n",
      "  Actual: Missing Tests for load_data | api_handler.py | 11-14 | 9 | Test Gap...\n",
      "\n",
      "  Expected: Missing test coverage for read_user_file including path traversal attempts, file not found, permission errors\n",
      "  Matched: True\n",
      "  Actual: Missing Tests for read_user_file | file_handler.py | 2-6 | 7 | Test Gap...\n",
      "\n",
      "  Expected: Missing test coverage for delete_file including path traversal attempts, file not found, permission errors\n",
      "  Matched: True\n",
      "  Actual: Missing Tests for delete_file | file_handler.py | 7-10 | 8 | Test Gap...\n",
      "\n",
      "============================================================\n",
      "CALCULATED METRICS:\n",
      "============================================================\n",
      "Recall: 0.67\n",
      "Precision: 0.77\n",
      "F1 Score: 0.71\n",
      "Status: ✗ FAILED\n",
      "\n",
      "============================================================\n",
      "TESTING: 05_multi_file_mixed\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "CALLING AGGREGATOR...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AGGREGATOR OUTPUT:\n",
      "============================================================\n",
      "# Code Review Report\n",
      "\n",
      "## Executive Summary\n",
      "The most critical issues identified across the codebase involve insecure password hashing with MD5 in user_manager.py and weak session token generation in session_manager.py, both of which pose significant security risks and should be prioritized for immediate remediation to prevent vulnerabilities like brute-force attacks and session hijacking. Additional concerns include unimplemented methods, inadequate email validation, missing error handling, and stylistic issues that impact code maintainability. Test coverage is notably lacking for key functions in both files, with gaps in normal, edge, and error scenarios that must be addressed to ensure robustness.\n",
      "\n",
      "## Summary of Actions\n",
      "| Issue | File | Lines | Severity | Category | Fix | Found By |\n",
      "|-------|------|-------|----------|----------|-----|----------|\n",
      "| Insecure Password Hashing Using MD5 | user_manager.py | [3,4,5,6,7,8,9,10] | 9 | Security | Replace MD5 with a secure password hashing library like bcrypt with salt, for example: bcrypt.hashpw(password.encode(), bcrypt.gensalt()).decode(). | Code Analyzer, Security, Best Practices |\n",
      "| Unimplemented fetch_user Method Leading to Potential Runtime Errors | user_manager.py | [11,12] | 7 | Bug | Implement the fetch_user(index) method or replace the call with appropriate user fetching logic. | Code Analyzer |\n",
      "| Email Validation Method Unconditionally Returns True | user_manager.py | [16,17] | 6 | Bug | Implement proper email validation using regex or a validation library to verify the email format. | Code Analyzer, Best Practices |\n",
      "| Missing docstrings in class and methods | user_manager.py | [1,3,6,11,15] | 4 | Style | Add descriptive docstrings for classes and all methods explaining their purpose, parameters, and return values. | Best Practices |\n",
      "| Unclear variable name 'hash' | user_manager.py | [7] | 4 | Style | Rename variable 'hash' to a more descriptive name such as 'password_hash' or 'hashed_password'. | Best Practices |\n",
      "| Missing try-except blocks for error-prone operations | user_manager.py | [7] | 5 | Bug | Wrap sensitive operations in try-except blocks to catch and handle potential exceptions gracefully. | Best Practices |\n",
      "| Test Gap: create_user | user_manager.py | [3,9] | 8 | Test Gap | Unit tests for normal input (valid username, password, email), edge cases (empty or very long inputs), error conditions (None or invalid types), and integration (verify MD5 hash matches input). | Test Coverage |\n",
      "| Test Gap: get_users | user_manager.py | [10,17] | 7 | Test Gap | Unit and integration tests for normal input (positive count), edge cases (zero, negative, large count), and error conditions (fetch_user exceptions, interactions with fetch_user). | Test Coverage |\n",
      "| Test Gap: validate_email | user_manager.py | [18,20] | 6 | Test Gap | Unit tests for normal input (valid emails), edge cases (empty, invalid formats, None), and integration (usage in create_user or registration). | Test Coverage |\n",
      "| Insecure Session Token Generation | session_manager.py | [3,4,5,6,7,8,9,10] | 9 | Security | Use Python's secrets module to generate secure random tokens, e.g., secrets.token_hex(16) or secrets.token_urlsafe(16), instead of random.randint for cryptographic security. | Code Analyzer, Security |\n",
      "| Simplistic Session Token Validation | session_manager.py | [12,13,14] | 6 | Bug | Implement proper session validation logic that verifies the token against stored session data and checks for expiration. | Code Analyzer |\n",
      "| Magic number in generate_token | session_manager.py | [5,7] | 3 | Style | Define a constant TOKEN_LENGTH = 16 at the class or module level to clarify the purpose and facilitate future changes. | Best Practices |\n",
      "| Inefficient token generation logic | session_manager.py | [6,7,8,9] | 3 | Performance | Use a list comprehension or join method: token = ''.join(str(random.randint(0, 9)) for _ in range(TOKEN_LENGTH)) to improve performance and readability. | Best Practices |\n",
      "| Test Gap: generate_token | session_manager.py | [3,10] | 7 | Test Gap | Unit tests for normal input (16-digit length), edge case (randomness distribution), error conditions (output type/length consistency), and integration (usage in session flow). | Test Coverage |\n",
      "| Test Gap: validate_session | session_manager.py | [11,15] | 7 | Test Gap | Unit tests for normal input (valid non-empty token), edge cases (empty string, None), and error conditions (incorrect types like int or list). | Test Coverage |\n",
      "\n",
      "**Total Distinct Issues: 15**\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "JUDGE OUTPUT:\n",
      "============================================================\n",
      "total_expected: 16\n",
      "total_actual: 15\n",
      "matches: 12\n",
      "\n",
      "matched_findings:\n",
      "\n",
      "  Expected: Weak cryptographic hash algorithm (MD5) used for password hashing in create_user\n",
      "  Matched: True\n",
      "  Actual: Insecure Password Hashing Using MD5...\n",
      "\n",
      "  Expected: Cryptographically insecure random number generator (random.randint) used for token generation\n",
      "  Matched: True\n",
      "  Actual: Insecure Session Token Generation...\n",
      "\n",
      "  Expected: Weak session validation in validate_session - only checks if token exists, not authenticity or expiry\n",
      "  Matched: True\n",
      "  Actual: Simplistic Session Token Validation...\n",
      "\n",
      "  Expected: validate_email always returns True without any actual email validation logic\n",
      "  Matched: True\n",
      "  Actual: Email Validation Method Unconditionally Returns True...\n",
      "\n",
      "  Expected: get_users calls undefined method fetch_user which will cause AttributeError at runtime\n",
      "  Matched: True\n",
      "  Actual: Unimplemented fetch_user Method Leading to Potential Runtime Errors...\n",
      "\n",
      "  Expected: Missing salt when hashing passwords in create_user\n",
      "  Matched: False\n",
      "\n",
      "  Expected: Token generation only uses digits (0-9) resulting in weak token space\n",
      "  Matched: False\n",
      "\n",
      "  Expected: validate_session can be simplified to return bool(token)\n",
      "  Matched: False\n",
      "\n",
      "  Expected: Missing docstrings for both classes and all methods\n",
      "  Matched: True\n",
      "  Actual: Missing docstrings in class and methods...\n",
      "\n",
      "  Expected: Missing error handling in get_users for when fetch_user fails\n",
      "  Matched: True\n",
      "  Actual: Missing try-except blocks for error-prone operations...\n",
      "\n",
      "  Expected: No validation that count parameter in get_users is positive\n",
      "  Matched: False\n",
      "\n",
      "  Expected: Missing test coverage for create_user including password hashing verification, edge cases for inputs\n",
      "  Matched: True\n",
      "  Actual: Test Gap: create_user...\n",
      "\n",
      "  Expected: Missing test coverage for generate_token including uniqueness, randomness quality, token strength\n",
      "  Matched: True\n",
      "  Actual: Test Gap: generate_token...\n",
      "\n",
      "  Expected: Missing test coverage for validate_email including valid/invalid email formats, edge cases\n",
      "  Matched: True\n",
      "  Actual: Test Gap: validate_email...\n",
      "\n",
      "  Expected: Missing test coverage for get_users including undefined fetch_user error, negative count, empty results\n",
      "  Matched: True\n",
      "  Actual: Test Gap: get_users...\n",
      "\n",
      "  Expected: Missing test coverage for validate_session including empty strings, None, expired tokens, forged tokens\n",
      "  Matched: True\n",
      "  Actual: Test Gap: validate_session...\n",
      "\n",
      "============================================================\n",
      "CALCULATED METRICS:\n",
      "============================================================\n",
      "Recall: 0.75\n",
      "Precision: 0.80\n",
      "F1 Score: 0.77\n",
      "Status: ✗ FAILED\n",
      "\n",
      "\n",
      "============================================================\n",
      "OVERALL SUMMARY\n",
      "============================================================\n",
      "✗ 01_sql_injection: R=1.00 P=0.83 F1=0.91\n",
      "✓ 02_logic_bug: R=0.83 P=1.00 F1=0.91\n",
      "✗ 03_code_quality: R=0.78 P=1.00 F1=0.88\n",
      "✗ 04_multi_file_security: R=0.67 P=0.77 F1=0.71\n",
      "✗ 05_multi_file_mixed: R=0.75 P=0.80 F1=0.77\n",
      "\n",
      "Passed: 1/5\n"
     ]
    }
   ],
   "source": [
    "# test all test cases\n",
    "\n",
    "test_cases = [\n",
    "    \"01_sql_injection\",\n",
    "    \"02_logic_bug\",\n",
    "    \"03_code_quality\",\n",
    "    \"04_multi_file_security\",\n",
    "    \"05_multi_file_mixed\"\n",
    "]\n",
    "\n",
    "async def run_all_tests():\n",
    "    test_dir = Path(\"test-cases\")\n",
    "    results = []\n",
    "    \n",
    "    for test_name in test_cases:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"TESTING: {test_name}\")\n",
    "        print('='*60)\n",
    "        \n",
    "        # Load files\n",
    "        diff_file = test_dir / f\"{test_name}.diff\"\n",
    "        diff_content = diff_file.read_text()\n",
    "        expected_file = test_dir / f\"{test_name}_expected.json\"\n",
    "        ground_truth_content = expected_file.read_text()\n",
    "        \n",
    "        # Run review\n",
    "        report = await review_code(diff_content, save_output=False)\n",
    "        \n",
    "        # Evaluate\n",
    "        eval_result = await evaluate_report(report, ground_truth_content)\n",
    "        \n",
    "        # Print detailed judge output\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"JUDGE OUTPUT:\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"total_expected: {eval_result['total_expected']}\")\n",
    "        print(f\"total_actual: {eval_result['total_actual']}\")\n",
    "        print(f\"matches: {eval_result['matches']}\")\n",
    "        print(f\"\\nmatched_findings:\")\n",
    "        for mf in eval_result['details']:\n",
    "            print(f\"\\n  Expected: {mf.expected}\")\n",
    "            print(f\"  Matched: {mf.matched}\")\n",
    "            if mf.actual_finding:\n",
    "                print(f\"  Actual: {mf.actual_finding[:100]}...\")\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'test_name': test_name,\n",
    "            'recall': eval_result['recall'],\n",
    "            'precision': eval_result['precision'],\n",
    "            'f1': eval_result['f1'],\n",
    "            'passed': eval_result['recall'] >= 0.80 and \n",
    "                     eval_result['precision'] >= 0.85 and \n",
    "                     eval_result['f1'] >= 0.82\n",
    "        })\n",
    "        \n",
    "        # Print calculated metrics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CALCULATED METRICS:\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Recall: {eval_result['recall']:.2f}\")\n",
    "        print(f\"Precision: {eval_result['precision']:.2f}\")\n",
    "        print(f\"F1 Score: {eval_result['f1']:.2f}\")\n",
    "        print(f\"Status: {'✓ PASSED' if results[-1]['passed'] else '✗ FAILED'}\")\n",
    "    \n",
    "    # Print overall summary\n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(\"OVERALL SUMMARY\")\n",
    "    print('='*60)\n",
    "    for result in results:\n",
    "        status = '✓' if result['passed'] else '✗'\n",
    "        print(f\"{status} {result['test_name']}: R={result['recall']:.2f} P={result['precision']:.2f} F1={result['f1']:.2f}\")\n",
    "    \n",
    "    passed = sum(1 for r in results if r['passed'])\n",
    "    print(f\"\\nPassed: {passed}/{len(results)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run all tests\n",
    "results = await run_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32dd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-review",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
